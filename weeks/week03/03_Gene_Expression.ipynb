{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Expression\n",
    "\n",
    "([**Return to Week 3 index.**](http://localhost:8890/tree/Desktop/BIOM262/week03#))\n",
    "\n",
    "\n",
    "## Table of Contents (Problems)\n",
    "[**A.**](#A.)  \n",
    "[**B.**](#B.)  \n",
    "[**C.**](#C.)  \n",
    "[**D.**](#D.)\n",
    "\n",
    "* * *\n",
    "\n",
    "## Data Set\n",
    "\n",
    "Expression of six clustered genes is proposed to be up-regulated by transcription of an adjacent lncRNA, hotsix. Below are relative quantity measures for each of the six gene  from explicitly paired samples of animals that have or do not have hotsix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>animal</th><th scope=col>pair</th><th scope=col>hotsix</th><th scope=col>lukewarm</th><th scope=col>tepid</th><th scope=col>mild1</th><th scope=col>athermal</th><th scope=col>bathwater</th><th scope=col>coldshower</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>3011</td><td>1</td><td>-</td><td>0.4202</td><td>1.075</td><td>0.3974</td><td>0.9355</td><td>0.4695</td><td>0.1688</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>3022</td><td>2</td><td>-</td><td>0.4718</td><td>1.0288</td><td>1.2747</td><td>0.6859</td><td>0.5616</td><td>0.4862</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3026</td><td>3</td><td>-</td><td>0.5351</td><td>0.9428</td><td>1.0208</td><td>0.5423</td><td>0.1972</td><td>0.2022</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>3045</td><td>4</td><td>-</td><td>0.4955</td><td>0.7869</td><td>0.9073</td><td>0.6276</td><td>0.1854</td><td>0.2918</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>3052</td><td>5</td><td>-</td><td>0.4299</td><td>0.9417</td><td>1.3223</td><td>0.8431</td><td>0.3982</td><td>0.3084</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>3059</td><td>6</td><td>-</td><td>0.5609</td><td>1.232</td><td>0.4473</td><td>1.5524</td><td>0.2859</td><td>0.1451</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>3066</td><td>7</td><td>-</td><td>1.4554</td><td>1.0419</td><td>0.6562</td><td>1.4554</td><td>0.4248</td><td>0.1613</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>3080</td><td>8</td><td>-</td><td>0.8959</td><td>0.7659</td><td>0.4807</td><td>1.1754</td><td>0.2734</td><td>0.1762</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>3082</td><td>9</td><td>-</td><td>0.3992</td><td>0.7921</td><td>1.4045</td><td>0.9383</td><td>0.472</td><td>0.3975</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>3110</td><td>10</td><td>-</td><td>0.3526</td><td>0.7998</td><td>1.2606</td><td>0.8413</td><td>0.4511</td><td>0.3654</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>3118</td><td>11</td><td>-</td><td>0.4693</td><td>1.0066</td><td>1.1801</td><td>1.0622</td><td>0.4872</td><td>0.2672</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>3012</td><td>1</td><td>+</td><td>0.444</td><td>1.4432</td><td>0.4406</td><td>1.6114</td><td>0.4515</td><td>0.2432</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>3020</td><td>2</td><td>+</td><td>0.6421</td><td>1.0284</td><td>1.3161</td><td>0.8921</td><td>0.6262</td><td>0.54</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>3023</td><td>3</td><td>+</td><td>0.476</td><td>0.7981</td><td>1</td><td>0.5934</td><td>0.231</td><td>0.3009</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>3040</td><td>4</td><td>+</td><td>0.6719</td><td>0.8398</td><td>1.274</td><td>0.7259</td><td>0.2996</td><td>0.3784</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>3049</td><td>5</td><td>+</td><td>0.5112</td><td>0.9713</td><td>1.3513</td><td>0.7823</td><td>0.3387</td><td>0.403</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>3056</td><td>6</td><td>+</td><td>0.6103</td><td>1.3715</td><td>0.51</td><td>1.7307</td><td>0.3617</td><td>0.1874</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>3079</td><td>7</td><td>+</td><td>1.6036</td><td>1.1495</td><td>0.7285</td><td>1.3375</td><td>0.4124</td><td>0.2952</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>3081</td><td>8</td><td>+</td><td>1.1222</td><td>0.8942</td><td>0.513</td><td>1.2949</td><td>0.4346</td><td>0.2583</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>3085</td><td>9</td><td>+</td><td>0.4161</td><td>0.9395</td><td>1.1992</td><td>0.9451</td><td>0.6665</td><td>0.4637</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>3107</td><td>10</td><td>+</td><td>0.5402</td><td>0.9351</td><td>1.3654</td><td>1.0016</td><td>0.5347</td><td>0.5092</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>3121</td><td>11</td><td>+</td><td>0.4242</td><td>1.2581</td><td>1.311</td><td>1.1429</td><td>0.5469</td><td>0.4098</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       "  & animal & pair & hotsix & lukewarm & tepid & mild1 & athermal & bathwater & coldshower\\\\\n",
       "\\hline\n",
       "\t1 & 3011 & 1 & - & 0.4202 & 1.075 & 0.3974 & 0.9355 & 0.4695 & 0.1688\\\\\n",
       "\t2 & 3022 & 2 & - & 0.4718 & 1.0288 & 1.2747 & 0.6859 & 0.5616 & 0.4862\\\\\n",
       "\t3 & 3026 & 3 & - & 0.5351 & 0.9428 & 1.0208 & 0.5423 & 0.1972 & 0.2022\\\\\n",
       "\t4 & 3045 & 4 & - & 0.4955 & 0.7869 & 0.9073 & 0.6276 & 0.1854 & 0.2918\\\\\n",
       "\t5 & 3052 & 5 & - & 0.4299 & 0.9417 & 1.3223 & 0.8431 & 0.3982 & 0.3084\\\\\n",
       "\t6 & 3059 & 6 & - & 0.5609 & 1.232 & 0.4473 & 1.5524 & 0.2859 & 0.1451\\\\\n",
       "\t7 & 3066 & 7 & - & 1.4554 & 1.0419 & 0.6562 & 1.4554 & 0.4248 & 0.1613\\\\\n",
       "\t8 & 3080 & 8 & - & 0.8959 & 0.7659 & 0.4807 & 1.1754 & 0.2734 & 0.1762\\\\\n",
       "\t9 & 3082 & 9 & - & 0.3992 & 0.7921 & 1.4045 & 0.9383 & 0.472 & 0.3975\\\\\n",
       "\t10 & 3110 & 10 & - & 0.3526 & 0.7998 & 1.2606 & 0.8413 & 0.4511 & 0.3654\\\\\n",
       "\t11 & 3118 & 11 & - & 0.4693 & 1.0066 & 1.1801 & 1.0622 & 0.4872 & 0.2672\\\\\n",
       "\t12 & 3012 & 1 & + & 0.444 & 1.4432 & 0.4406 & 1.6114 & 0.4515 & 0.2432\\\\\n",
       "\t13 & 3020 & 2 & + & 0.6421 & 1.0284 & 1.3161 & 0.8921 & 0.6262 & 0.54\\\\\n",
       "\t14 & 3023 & 3 & + & 0.476 & 0.7981 & 1 & 0.5934 & 0.231 & 0.3009\\\\\n",
       "\t15 & 3040 & 4 & + & 0.6719 & 0.8398 & 1.274 & 0.7259 & 0.2996 & 0.3784\\\\\n",
       "\t16 & 3049 & 5 & + & 0.5112 & 0.9713 & 1.3513 & 0.7823 & 0.3387 & 0.403\\\\\n",
       "\t17 & 3056 & 6 & + & 0.6103 & 1.3715 & 0.51 & 1.7307 & 0.3617 & 0.1874\\\\\n",
       "\t18 & 3079 & 7 & + & 1.6036 & 1.1495 & 0.7285 & 1.3375 & 0.4124 & 0.2952\\\\\n",
       "\t19 & 3081 & 8 & + & 1.1222 & 0.8942 & 0.513 & 1.2949 & 0.4346 & 0.2583\\\\\n",
       "\t20 & 3085 & 9 & + & 0.4161 & 0.9395 & 1.1992 & 0.9451 & 0.6665 & 0.4637\\\\\n",
       "\t21 & 3107 & 10 & + & 0.5402 & 0.9351 & 1.3654 & 1.0016 & 0.5347 & 0.5092\\\\\n",
       "\t22 & 3121 & 11 & + & 0.4242 & 1.2581 & 1.311 & 1.1429 & 0.5469 & 0.4098\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   animal pair hotsix lukewarm  tepid  mild1 athermal bathwater coldshower\n",
       "1    3011    1      -   0.4202 1.0750 0.3974   0.9355    0.4695     0.1688\n",
       "2    3022    2      -   0.4718 1.0288 1.2747   0.6859    0.5616     0.4862\n",
       "3    3026    3      -   0.5351 0.9428 1.0208   0.5423    0.1972     0.2022\n",
       "4    3045    4      -   0.4955 0.7869 0.9073   0.6276    0.1854     0.2918\n",
       "5    3052    5      -   0.4299 0.9417 1.3223   0.8431    0.3982     0.3084\n",
       "6    3059    6      -   0.5609 1.2320 0.4473   1.5524    0.2859     0.1451\n",
       "7    3066    7      -   1.4554 1.0419 0.6562   1.4554    0.4248     0.1613\n",
       "8    3080    8      -   0.8959 0.7659 0.4807   1.1754    0.2734     0.1762\n",
       "9    3082    9      -   0.3992 0.7921 1.4045   0.9383    0.4720     0.3975\n",
       "10   3110   10      -   0.3526 0.7998 1.2606   0.8413    0.4511     0.3654\n",
       "11   3118   11      -   0.4693 1.0066 1.1801   1.0622    0.4872     0.2672\n",
       "12   3012    1      +   0.4440 1.4432 0.4406   1.6114    0.4515     0.2432\n",
       "13   3020    2      +   0.6421 1.0284 1.3161   0.8921    0.6262     0.5400\n",
       "14   3023    3      +   0.4760 0.7981 1.0000   0.5934    0.2310     0.3009\n",
       "15   3040    4      +   0.6719 0.8398 1.2740   0.7259    0.2996     0.3784\n",
       "16   3049    5      +   0.5112 0.9713 1.3513   0.7823    0.3387     0.4030\n",
       "17   3056    6      +   0.6103 1.3715 0.5100   1.7307    0.3617     0.1874\n",
       "18   3079    7      +   1.6036 1.1495 0.7285   1.3375    0.4124     0.2952\n",
       "19   3081    8      +   1.1222 0.8942 0.5130   1.2949    0.4346     0.2583\n",
       "20   3085    9      +   0.4161 0.9395 1.1992   0.9451    0.6665     0.4637\n",
       "21   3107   10      +   0.5402 0.9351 1.3654   1.0016    0.5347     0.5092\n",
       "22   3121   11      +   0.4242 1.2581 1.3110   1.1429    0.5469     0.4098"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot<-read.table(\"hot.txt\",head=T)\n",
    "hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. \n",
    "\n",
    "How would you analyze the data to test the hypothesis that hotsix + animals express a higher level than hotsix - for each of these thermally-named genes?  \n",
    "  \n",
    "#### Perform this analysis in R and report appropriate p-values for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hot<-read.table(\"hot.txt\",head=T)\n",
    "attach(hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the samples are explicitly paired, the normality that matters for the t test is the difference between samples, e.g.: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>lm</th><th scope=col>lp</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.4202</td><td>0.4440</td></tr>\n",
       "\t<tr><td>0.4718</td><td>0.6421</td></tr>\n",
       "\t<tr><td>0.5351</td><td>0.4760</td></tr>\n",
       "\t<tr><td>0.4955</td><td>0.6719</td></tr>\n",
       "\t<tr><td>0.4299</td><td>0.5112</td></tr>\n",
       "\t<tr><td>0.5609</td><td>0.6103</td></tr>\n",
       "\t<tr><td>1.4554</td><td>1.6036</td></tr>\n",
       "\t<tr><td>0.8959</td><td>1.1222</td></tr>\n",
       "\t<tr><td>0.3992</td><td>0.4161</td></tr>\n",
       "\t<tr><td>0.3526</td><td>0.5402</td></tr>\n",
       "\t<tr><td>0.4693</td><td>0.4242</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " lm & lp\\\\\n",
       "\\hline\n",
       "\t 0.4202 & 0.4440\\\\\n",
       "\t 0.4718 & 0.6421\\\\\n",
       "\t 0.5351 & 0.4760\\\\\n",
       "\t 0.4955 & 0.6719\\\\\n",
       "\t 0.4299 & 0.5112\\\\\n",
       "\t 0.5609 & 0.6103\\\\\n",
       "\t 1.4554 & 1.6036\\\\\n",
       "\t 0.8959 & 1.1222\\\\\n",
       "\t 0.3992 & 0.4161\\\\\n",
       "\t 0.3526 & 0.5402\\\\\n",
       "\t 0.4693 & 0.4242\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. 0.4202\n",
       "2. 0.4718\n",
       "3. 0.5351\n",
       "4. 0.4955\n",
       "5. 0.4299\n",
       "6. 0.5609\n",
       "7. 1.4554\n",
       "8. 0.8959\n",
       "9. 0.3992\n",
       "10. 0.3526\n",
       "11. 0.4693\n",
       "12. 0.444\n",
       "13. 0.6421\n",
       "14. 0.476\n",
       "15. 0.6719\n",
       "16. 0.5112\n",
       "17. 0.6103\n",
       "18. 1.6036\n",
       "19. 1.1222\n",
       "20. 0.4161\n",
       "21. 0.5402\n",
       "22. 0.4242\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "          lm     lp\n",
       " [1,] 0.4202 0.4440\n",
       " [2,] 0.4718 0.6421\n",
       " [3,] 0.5351 0.4760\n",
       " [4,] 0.4955 0.6719\n",
       " [5,] 0.4299 0.5112\n",
       " [6,] 0.5609 0.6103\n",
       " [7,] 1.4554 1.6036\n",
       " [8,] 0.8959 1.1222\n",
       " [9,] 0.3992 0.4161\n",
       "[10,] 0.3526 0.5402\n",
       "[11,] 0.4693 0.4242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm<-lukewarm[1:11]\n",
    "lp<-lukewarm[12:22]\n",
    "luke<-cbind(lm,lp)\n",
    "luke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.0238</li>\n",
       "\t<li>-0.1703</li>\n",
       "\t<li>0.0591</li>\n",
       "\t<li>-0.1764</li>\n",
       "\t<li>-0.0813</li>\n",
       "\t<li>-0.0494</li>\n",
       "\t<li>-0.1482</li>\n",
       "\t<li>-0.2263</li>\n",
       "\t<li>-0.0169</li>\n",
       "\t<li>-0.1876</li>\n",
       "\t<li>0.0451</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.0238\n",
       "\\item -0.1703\n",
       "\\item 0.0591\n",
       "\\item -0.1764\n",
       "\\item -0.0813\n",
       "\\item -0.0494\n",
       "\\item -0.1482\n",
       "\\item -0.2263\n",
       "\\item -0.0169\n",
       "\\item -0.1876\n",
       "\\item 0.0451\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.0238\n",
       "2. -0.1703\n",
       "3. 0.0591\n",
       "4. -0.1764\n",
       "5. -0.0813\n",
       "6. -0.0494\n",
       "7. -0.1482\n",
       "8. -0.2263\n",
       "9. -0.0169\n",
       "10. -0.1876\n",
       "11. 0.0451\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] -0.0238 -0.1703  0.0591 -0.1764 -0.0813 -0.0494 -0.1482 -0.2263 -0.0169\n",
       "[10] -0.1876  0.0451"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm-lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test normality of the difference between hotsix+ and hotsix- for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  lp - lm\n",
       "W = 0.93038, p-value = 0.4147\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapiro.test(lp-lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and equality of variance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tF test to compare two variances\n",
       "\n",
       "data:  lm and lp\n",
       "F = 0.77213, num df = 10, denom df = 10, p-value = 0.6904\n",
       "alternative hypothesis: true ratio of variances is not equal to 1\n",
       "95 percent confidence interval:\n",
       " 0.2077404 2.8698384\n",
       "sample estimates:\n",
       "ratio of variances \n",
       "         0.7721278 \n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.test(lm,lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "|   | lukewarm | tepid | mild1 | athermal | bathwater | coldshower |  \n",
    " | -------- |------ | ----- | -------- | --------- | ---------- |\n",
    " | Shapiro.test | 0.4147 | 0.7611 | 0.06518 | 0.0129 | 0.9437 | 0.402 |  \n",
    " | var.test | 0.6904 | 0.2439 | 0.9675 | 0.7063 | 0.8103 | 0.939 |  \n",
    " \n",
    "Depending on what one believes about the evidence for/against normality in mild1 and athermal one could argue for either a parametric approach on the grounds that the lone “significant” departure is no more than one would expect by chance in 6 assays, or one may argue that at least two genes are not persuasively normal and a non-parametric approach should be more conservative and not too much less powerful.  \n",
    "  \n",
    "Each test provides evidence against the null hypothesis given certain assumptions and one may explain uncertainty in the assumptions and present both approaches, provided the rationale for doing so is clear and specified in advance. I would also accept an argument that, for this data structure, one might expect skewing of the distribution to be a specific function of the gene or assay and thus use t for most, but use the non-parametric test for athermal and possibly mild1.  \n",
    "  \n",
    "However one chooses to view it, the test or tests must be specified before performing either – one should even specify how possible outcomes of the normality and equality of variance tests will lead to the analysis before testing the data distributions. Any test must be paired-sample as this is explicit in the data collection. \n",
    "\n",
    "#### The question also specifies a directional hypothesis, so one tail is appropriate; e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tPaired t-test\n",
       "\n",
       "data:  lukewarm by hotsix\n",
       "t = -2.983, df = 10, p-value = 0.006868\n",
       "alternative hypothesis: true difference in means is less than 0\n",
       "95 percent confidence interval:\n",
       "        -Inf -0.03481709\n",
       "sample estimates:\n",
       "mean of the differences \n",
       "            -0.08872727 \n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test(lukewarm~hotsix, paired=T, alternative=\"less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible nominal p-values:\n",
    "\n",
    "|  | lukewarm | tepid | mild1 | athermal | bathwater | coldshower |\n",
    " | -------- |------ | ----- | -------- | --------- | ---------- |\n",
    "| paired t | 0.006868 | 0.01013 | 0.08552 | 0.03468 | 0.01015 | 2.429e-06 |\n",
    "| Wilcoxon signed rank | 0.01221 | 0.01611 | 0.02686 | 0.01611 | 0.009277 | 0.0004883 |\n",
    "| Mixed by normality | 0.006868 | 0.01013 | 0.02686 | 0.01611 | 0.01015 | 2.429e-06 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "\n",
    "# B. \n",
    "To quantify the support for the independent hypotheses at each gene, one should control for type I error.  Adjust the p-values from A using Hommel’s method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt<-c(0.006868, 0.01013, 0.08552,\t0.03468, 0.01015, 2.429e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.020604</li>\n",
       "\t<li>0.03039</li>\n",
       "\t<li>0.08552</li>\n",
       "\t<li>0.06936</li>\n",
       "\t<li>0.03045</li>\n",
       "\t<li>1.4574e-05</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.020604\n",
       "\\item 0.03039\n",
       "\\item 0.08552\n",
       "\\item 0.06936\n",
       "\\item 0.03045\n",
       "\\item 1.4574e-05\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.020604\n",
       "2. 0.03039\n",
       "3. 0.08552\n",
       "4. 0.06936\n",
       "5. 0.03045\n",
       "6. 1.4574e-05\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2.0604e-02 3.0390e-02 8.5520e-02 6.9360e-02 3.0450e-02 1.4574e-05"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.adjust(pt,method=\"hommel\",6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible adjusted p-values:\n",
    "\n",
    "|  | lukewarm | tepid | mild1 | athermal | bathwater | coldshower |\n",
    " | -------- |------ | ----- | -------- | --------- | ---------- |\n",
    "| paired t | 2.060e-02 | 3.039e-02 | 8.552e-02 | 6.936e-02 | 3.045e-02 | 1.457e-05 |  \n",
    "| Wilcoxon signed rank | 0.02442 | 0.02686 | 0.02686 | 0.02686 | 0.02416 | 0.00293 |  \n",
    "| Mixed by normality | 2.060e-02 | 2.417e-02 | 2.686e-02 | 2.686e-02 | 2.417e-02 | 1.457e-05 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "# C.\n",
    "\n",
    "How would you use this data to test the hypothesis that hotsix has the predicted effect on expression of these six genes as a group?  \n",
    "\n",
    "#### Perform the test in R and report an appropriate p-value.\n",
    "\n",
    "I show two possible approaches, others approaches were also acceptable for full credit if they were explained and fit the data structure.\n",
    ".\n",
    "##### 1. Simple, back-of-the-envelope approach using methods shown in class: pool data for single test.\n",
    "hotsix- samples retain header lm and hotsix+ lp, from luke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'hot'</li>\n",
       "\t<li>'lm'</li>\n",
       "\t<li>'lp'</li>\n",
       "\t<li>'luke'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'hot'\n",
       "\\item 'lm'\n",
       "\\item 'lp'\n",
       "\\item 'luke'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'hot'\n",
       "2. 'lm'\n",
       "3. 'lp'\n",
       "4. 'luke'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"hot\"  \"lm\"   \"lp\"   \"luke\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>lm</th><th scope=col>lp</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.4202</td><td>0.4440</td></tr>\n",
       "\t<tr><td>0.4718</td><td>0.6421</td></tr>\n",
       "\t<tr><td>0.5351</td><td>0.4760</td></tr>\n",
       "\t<tr><td>0.4955</td><td>0.6719</td></tr>\n",
       "\t<tr><td>0.4299</td><td>0.5112</td></tr>\n",
       "\t<tr><td>0.5609</td><td>0.6103</td></tr>\n",
       "\t<tr><td>1.4554</td><td>1.6036</td></tr>\n",
       "\t<tr><td>0.8959</td><td>1.1222</td></tr>\n",
       "\t<tr><td>0.3992</td><td>0.4161</td></tr>\n",
       "\t<tr><td>0.3526</td><td>0.5402</td></tr>\n",
       "\t<tr><td>0.4693</td><td>0.4242</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " lm & lp\\\\\n",
       "\\hline\n",
       "\t 0.4202 & 0.4440\\\\\n",
       "\t 0.4718 & 0.6421\\\\\n",
       "\t 0.5351 & 0.4760\\\\\n",
       "\t 0.4955 & 0.6719\\\\\n",
       "\t 0.4299 & 0.5112\\\\\n",
       "\t 0.5609 & 0.6103\\\\\n",
       "\t 1.4554 & 1.6036\\\\\n",
       "\t 0.8959 & 1.1222\\\\\n",
       "\t 0.3992 & 0.4161\\\\\n",
       "\t 0.3526 & 0.5402\\\\\n",
       "\t 0.4693 & 0.4242\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. 0.4202\n",
       "2. 0.4718\n",
       "3. 0.5351\n",
       "4. 0.4955\n",
       "5. 0.4299\n",
       "6. 0.5609\n",
       "7. 1.4554\n",
       "8. 0.8959\n",
       "9. 0.3992\n",
       "10. 0.3526\n",
       "11. 0.4693\n",
       "12. 0.444\n",
       "13. 0.6421\n",
       "14. 0.476\n",
       "15. 0.6719\n",
       "16. 0.5112\n",
       "17. 0.6103\n",
       "18. 1.6036\n",
       "19. 1.1222\n",
       "20. 0.4161\n",
       "21. 0.5402\n",
       "22. 0.4242\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "          lm     lp\n",
       " [1,] 0.4202 0.4440\n",
       " [2,] 0.4718 0.6421\n",
       " [3,] 0.5351 0.4760\n",
       " [4,] 0.4955 0.6719\n",
       " [5,] 0.4299 0.5112\n",
       " [6,] 0.5609 0.6103\n",
       " [7,] 1.4554 1.6036\n",
       " [8,] 0.8959 1.1222\n",
       " [9,] 0.3992 0.4161\n",
       "[10,] 0.3526 0.5402\n",
       "[11,] 0.4693 0.4242"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked from hot (pos = 3):\n",
      "\n",
      "    animal, athermal, bathwater, coldshower, hotsix, lukewarm, mild1,\n",
      "    pair, tepid\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  lm - lp\n",
       "W = 0.93038, p-value = 0.4147\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls()\n",
    "luke\n",
    "attach(hot)\n",
    "pool<-rbind(lukewarm,tepid,mild1,athermal,bathwater,coldshower)\n",
    "shapiro.test(lm-lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tF test to compare two variances\n",
       "\n",
       "data:  lm and lp\n",
       "F = 0.77213, num df = 10, denom df = 10, p-value = 0.6904\n",
       "alternative hypothesis: true ratio of variances is not equal to 1\n",
       "95 percent confidence interval:\n",
       " 0.2077404 2.8698384\n",
       "sample estimates:\n",
       "ratio of variances \n",
       "         0.7721278 \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.test(lm,lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWilcoxon signed rank test\n",
       "\n",
       "data:  lm and lp\n",
       "V = 8, p-value = 0.01221\n",
       "alternative hypothesis: true location shift is less than 0\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcox.test(lm,lp,paired=T,alternative=\"less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Meta-analysis, which you would have had to find on your own. \n",
    "\n",
    "(Here is one example, using Fisher’s classic test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fisher.test<-function(p){\n",
    "    Xsq <- -2*sum(log(p))\n",
    "    p.val <-pchisq(Xsq, df=2*length(p),lower.tail=FALSE)\n",
    "    return(c(Xsq=Xsq,p.value=p.val))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta-analysis based on paired t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.490719199598324</li>\n",
       "\t<li>0.433933029777887</li>\n",
       "\t<li>0.523033767366567</li>\n",
       "\t<li>0.43159271916227</li>\n",
       "\t<li>0.468331887986867</li>\n",
       "\t<li>0.480743050155333</li>\n",
       "\t<li>0.442433353570392</li>\n",
       "\t<li>0.412559112937683</li>\n",
       "\t<li>0.49340951534273</li>\n",
       "\t<li>0.427302949495238</li>\n",
       "\t<li>0.517582035975033</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.490719199598324\n",
       "\\item 0.433933029777887\n",
       "\\item 0.523033767366567\n",
       "\\item 0.43159271916227\n",
       "\\item 0.468331887986867\n",
       "\\item 0.480743050155333\n",
       "\\item 0.442433353570392\n",
       "\\item 0.412559112937683\n",
       "\\item 0.49340951534273\n",
       "\\item 0.427302949495238\n",
       "\\item 0.517582035975033\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.490719199598324\n",
       "2. 0.433933029777887\n",
       "3. 0.523033767366567\n",
       "4. 0.43159271916227\n",
       "5. 0.468331887986867\n",
       "6. 0.480743050155333\n",
       "7. 0.442433353570392\n",
       "8. 0.412559112937683\n",
       "9. 0.49340951534273\n",
       "10. 0.427302949495238\n",
       "11. 0.517582035975033\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.4907192 0.4339330 0.5230338 0.4315927 0.4683319 0.4807431 0.4424334\n",
       " [8] 0.4125591 0.4934095 0.4273029 0.5175820"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Xsq</dt>\n",
       "\t\t<dd>16.8844743020913</dd>\n",
       "\t<dt>p.value</dt>\n",
       "\t\t<dd>0.769705446079138</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Xsq] 16.8844743020913\n",
       "\\item[p.value] 0.769705446079138\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Xsq\n",
       ":   16.8844743020913p.value\n",
       ":   0.769705446079138\n",
       "\n"
      ],
      "text/plain": [
       "       Xsq    p.value \n",
       "16.8844743  0.7697054 "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=pt(lm-lp, 11)\n",
    "p\n",
    "Fisher.test(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta-analysis based on Wilcoxon rank sum tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for TDist {stats}\"><tr><td>TDist {stats}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>The Student t Distribution</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Density, distribution function, quantile function and random\n",
       "generation for the t distribution with <code>df</code> degrees of freedom\n",
       "(and optional non-centrality parameter <code>ncp</code>).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "dt(x, df, ncp, log = FALSE)\n",
       "pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)\n",
       "qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)\n",
       "rt(n, df, ncp)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>x, q</code></td>\n",
       "<td>\n",
       "<p>vector of quantiles.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>p</code></td>\n",
       "<td>\n",
       "<p>vector of probabilities.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>n</code></td>\n",
       "<td>\n",
       "<p>number of observations. If <code>length(n) &gt; 1</code>, the length\n",
       "is taken to be the number required.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>df</code></td>\n",
       "<td>\n",
       "<p>degrees of freedom (<i>&gt; 0</i>, maybe non-integer).  <code>df\n",
       "      = Inf</code> is allowed.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>ncp</code></td>\n",
       "<td>\n",
       "<p>non-centrality parameter <i>delta</i>;\n",
       "currently except for <code>rt()</code>, only for <code>abs(ncp) &lt;= 37.62</code>.\n",
       "If omitted, use the central t distribution.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>log, log.p</code></td>\n",
       "<td>\n",
       "<p>logical; if TRUE, probabilities p are given as log(p).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>lower.tail</code></td>\n",
       "<td>\n",
       "<p>logical; if TRUE (default), probabilities are\n",
       "<i>P[X &le; x]</i>, otherwise, <i>P[X &gt; x]</i>.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The <i>t</i> distribution with <code>df</code> <i>= n</i> degrees of\n",
       "freedom has density\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>f(x) = &Gamma;((n+1)/2) / (&radic;(n &pi;) &Gamma;(n/2)) (1 + x^2/n)^-((n+1)/2)</i></p>\n",
       "\n",
       "<p>for all real <i>x</i>.\n",
       "It has mean <i>0</i> (for <i>n &gt; 1</i>) and\n",
       "variance <i>n/(n-2)</i> (for <i>n &gt; 2</i>).\n",
       "</p>\n",
       "<p>The general <em>non-central</em> <i>t</i>\n",
       "with parameters <i>(df, Del)</i> <code>= (df, ncp)</code>\n",
       "is defined as the distribution of\n",
       "<i>T(df, Del) := (U + Del) / &radic;(V/df) </i>\n",
       "where <i>U</i> and <i>V</i>  are independent random\n",
       "variables, <i>U ~ N(0,1)</i> and\n",
       "<i>V ~ &chi;^2(df)</i> (see Chisquare).\n",
       "</p>\n",
       "<p>The most used applications are power calculations for <i>t</i>-tests:<br />\n",
       "Let <i>T= (mX - m0) / (S/sqrt(n))</i>\n",
       "where\n",
       "<i>mX</i> is the <code>mean</code> and <i>S</i> the sample standard\n",
       "deviation (<code>sd</code>) of <i>X_1, X_2, &hellip;, X_n</i> which are\n",
       "i.i.d. <i>N(&mu;, &sigma;^2)</i>\n",
       "Then <i>T</i> is distributed as non-central <i>t</i> with\n",
       "<code>df</code><i>= n - 1</i>\n",
       "degrees of freedom and <b>n</b>on-<b>c</b>entrality <b>p</b>arameter\n",
       "<code>ncp</code><i> = (&mu; - m0) * sqrt(n)/&sigma;</i>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p><code>dt</code> gives the density,\n",
       "<code>pt</code> gives the distribution function,\n",
       "<code>qt</code> gives the quantile function, and\n",
       "<code>rt</code> generates random deviates.\n",
       "</p>\n",
       "<p>Invalid arguments will result in return value <code>NaN</code>, with a warning.\n",
       "</p>\n",
       "<p>The length of the result is determined by <code>n</code> for\n",
       "<code>rt</code>, and is the maximum of the lengths of the\n",
       "numerical arguments for the other functions.  \n",
       "</p>\n",
       "<p>The numerical arguments other than <code>n</code> are recycled to the\n",
       "length of the result.  Only the first elements of the logical\n",
       "arguments are used.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "<p>Supplying <code>ncp = 0</code> uses the algorithm for the non-central\n",
       "distribution, which is not the same algorithm used if <code>ncp</code> is\n",
       "omitted.  This is to give consistent behaviour in extreme cases with\n",
       "values of <code>ncp</code> very near zero.\n",
       "</p>\n",
       "<p>The code for non-zero <code>ncp</code> is principally intended to be used\n",
       "for moderate values of <code>ncp</code>: it will not be highly accurate,\n",
       "especially in the tails, for large values.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Source</h3>\n",
       "\n",
       "<p>The central <code>dt</code> is computed via an accurate formula\n",
       "provided by Catherine Loader (see the reference in <code>dbinom</code>).\n",
       "</p>\n",
       "<p>For the non-central case of <code>dt</code>, C code contributed by\n",
       "Claus Ekstrøm based on the relationship (for\n",
       "<i>x != 0</i>) to the cumulative distribution.\n",
       "</p>\n",
       "<p>For the central case of <code>pt</code>, a normal approximation in the\n",
       "tails, otherwise via <code>pbeta</code>.\n",
       "</p>\n",
       "<p>For the non-central case of <code>pt</code> based on a C translation of\n",
       "</p>\n",
       "<p>Lenth, R. V. (1989). <em>Algorithm AS 243</em> &mdash;\n",
       "Cumulative distribution function of the non-central <i>t</i> distribution,\n",
       "<em>Applied Statistics</em> <b>38</b>, 185&ndash;189.\n",
       "</p>\n",
       "<p>This computes the lower tail only, so the upper tail suffers from\n",
       "cancellation and a warning will be given when this is likely to be\n",
       "significant.\n",
       "</p>\n",
       "<p>For central <code>qt</code>, a C translation of\n",
       "</p>\n",
       "<p>Hill, G. W. (1970) Algorithm 396: Student's t-quantiles.\n",
       "<em>Communications of the ACM</em>, <b>13(10)</b>, 619&ndash;620.\n",
       "</p>\n",
       "<p>altered to take account of\n",
       "</p>\n",
       "<p>Hill, G. W. (1981) Remark on Algorithm 396, <em>ACM Transactions on\n",
       "Mathematical Software</em>, <b>7</b>, 250&ndash;1.\n",
       "</p>\n",
       "<p>The non-central case is done by inversion.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)\n",
       "<em>The New S Language</em>.\n",
       "Wadsworth &amp; Brooks/Cole. (Except non-central versions.)\n",
       "</p>\n",
       "<p>Johnson, N. L., Kotz, S. and Balakrishnan, N. (1995)\n",
       "<em>Continuous Univariate Distributions</em>, volume 2, chapters 28 and 31.\n",
       "Wiley, New York.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p>Distributions for other standard distributions, including\n",
       "<code>df</code> for the F distribution.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "require(graphics)\n",
       "\n",
       "1 - pt(1:5, df = 1)\n",
       "qt(.975, df = c(1:10,20,50,100,1000))\n",
       "\n",
       "tt &lt;- seq(0, 10, len = 21)\n",
       "ncp &lt;- seq(0, 6, len = 31)\n",
       "ptn &lt;- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))\n",
       "t.tit &lt;- \"Non-central t - Probabilities\"\n",
       "image(tt, ncp, ptn, zlim = c(0,1), main = t.tit)\n",
       "persp(tt, ncp, ptn, zlim = 0:1, r = 2, phi = 20, theta = 200, main = t.tit,\n",
       "      xlab = \"t\", ylab = \"non-centrality parameter\",\n",
       "      zlab = \"Pr(T &lt;= t)\")\n",
       "\n",
       "plot(function(x) dt(x, df = 3, ncp = 2), -3, 11, ylim = c(0, 0.32),\n",
       "     main = \"Non-central t - Density\", yaxs = \"i\")\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>stats</em> version 3.2.2 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{TDist}{The Student t Distribution}{TDist}\n",
       "\\aliasA{dt}{TDist}{dt}\n",
       "\\aliasA{pt}{TDist}{pt}\n",
       "\\aliasA{qt}{TDist}{qt}\n",
       "\\aliasA{rt}{TDist}{rt}\n",
       "\\keyword{distribution}{TDist}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Density, distribution function, quantile function and random\n",
       "generation for the t distribution with \\code{df} degrees of freedom\n",
       "(and optional non-centrality parameter \\code{ncp}).\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "dt(x, df, ncp, log = FALSE)\n",
       "pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)\n",
       "qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)\n",
       "rt(n, df, ncp)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{x, q}] vector of quantiles.\n",
       "\\item[\\code{p}] vector of probabilities.\n",
       "\\item[\\code{n}] number of observations. If \\code{length(n) > 1}, the length\n",
       "is taken to be the number required.\n",
       "\\item[\\code{df}] degrees of freedom (\\eqn{> 0}{}, maybe non-integer).  \\code{df\n",
       "      = Inf} is allowed.\n",
       "\\item[\\code{ncp}] non-centrality parameter \\eqn{\\delta}{};\n",
       "currently except for \\code{rt()}, only for \\code{abs(ncp) <= 37.62}.\n",
       "If omitted, use the central t distribution.\n",
       "\\item[\\code{log, log.p}] logical; if TRUE, probabilities p are given as log(p).\n",
       "\\item[\\code{lower.tail}] logical; if TRUE (default), probabilities are\n",
       "\\eqn{P[X \\le x]}{}, otherwise, \\eqn{P[X > x]}{}.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The \\eqn{t}{} distribution with \\code{df} \\eqn{= \\nu}{} degrees of\n",
       "freedom has density\n",
       "\\deqn{\n",
       "    f(x) = \\frac{\\Gamma ((\\nu+1)/2)}{\\sqrt{\\pi \\nu} \\Gamma (\\nu/2)}\n",
       "    (1 + x^2/\\nu)^{-(\\nu+1)/2}%\n",
       "  }{}\n",
       "for all real \\eqn{x}{}.\n",
       "It has mean \\eqn{0}{} (for \\eqn{\\nu > 1}{}) and\n",
       "variance \\eqn{\\frac{\\nu}{\\nu-2}}{} (for \\eqn{\\nu > 2}{}).\n",
       "\n",
       "The general \\emph{non-central} \\eqn{t}{}\n",
       "with parameters \\eqn{(\\nu, \\delta)}{} \\code{= (df, ncp)}\n",
       "is defined as the distribution of\n",
       "\\eqn{T_{\\nu}(\\delta) := (U + \\delta)/\\sqrt{V/\\nu}}{}\n",
       "where \\eqn{U}{} and \\eqn{V}{}  are independent random\n",
       "variables, \\eqn{U \\sim {\\cal N}(0,1)}{} and\n",
       "\\eqn{V \\sim \\chi^2_\\nu}{} (see \\LinkA{Chisquare}{Chisquare}).\n",
       "\n",
       "The most used applications are power calculations for \\eqn{t}{}-tests:\\\\{}\n",
       "Let \\eqn{T = \\frac{\\bar{X} - \\mu_0}{S/\\sqrt{n}}}{}\n",
       "where\n",
       "\\eqn{\\bar{X}}{} is the \\code{\\LinkA{mean}{mean}} and \\eqn{S}{} the sample standard\n",
       "deviation (\\code{\\LinkA{sd}{sd}}) of \\eqn{X_1, X_2, \\dots, X_n}{} which are\n",
       "i.i.d. \\eqn{{\\cal N}(\\mu, \\sigma^2)}{}\n",
       "Then \\eqn{T}{} is distributed as non-central \\eqn{t}{} with\n",
       "\\code{df}\\eqn{{} = n-1}{}\n",
       "degrees of freedom and \\bold{n}on-\\bold{c}entrality \\bold{p}arameter\n",
       "\\code{ncp}\\eqn{{} = (\\mu - \\mu_0) \\sqrt{n}/\\sigma}{}.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "\\code{dt} gives the density,\n",
       "\\code{pt} gives the distribution function,\n",
       "\\code{qt} gives the quantile function, and\n",
       "\\code{rt} generates random deviates.\n",
       "\n",
       "Invalid arguments will result in return value \\code{NaN}, with a warning.\n",
       "\n",
       "The length of the result is determined by \\code{n} for\n",
       "\\code{rt}, and is the maximum of the lengths of the\n",
       "numerical arguments for the other functions.  \n",
       "\n",
       "The numerical arguments other than \\code{n} are recycled to the\n",
       "length of the result.  Only the first elements of the logical\n",
       "arguments are used.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Note}\\relax\n",
       "Supplying \\code{ncp = 0} uses the algorithm for the non-central\n",
       "distribution, which is not the same algorithm used if \\code{ncp} is\n",
       "omitted.  This is to give consistent behaviour in extreme cases with\n",
       "values of \\code{ncp} very near zero.\n",
       "\n",
       "The code for non-zero \\code{ncp} is principally intended to be used\n",
       "for moderate values of \\code{ncp}: it will not be highly accurate,\n",
       "especially in the tails, for large values.\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{Source}\\relax\n",
       "The central \\code{dt} is computed via an accurate formula\n",
       "provided by Catherine Loader (see the reference in \\code{\\LinkA{dbinom}{dbinom}}).\n",
       "\n",
       "For the non-central case of \\code{dt}, C code contributed by\n",
       "Claus Ekstrøm based on the relationship (for\n",
       "\\eqn{x \\neq 0}{}) to the cumulative distribution.\n",
       "\n",
       "For the central case of \\code{pt}, a normal approximation in the\n",
       "tails, otherwise via \\code{\\LinkA{pbeta}{pbeta}}.\n",
       "\n",
       "For the non-central case of \\code{pt} based on a C translation of\n",
       "\n",
       "Lenth, R. V. (1989). \\emph{Algorithm AS 243} ---\n",
       "Cumulative distribution function of the non-central \\eqn{t}{} distribution,\n",
       "\\emph{Applied Statistics} \\bold{38}, 185--189.\n",
       "\n",
       "This computes the lower tail only, so the upper tail suffers from\n",
       "cancellation and a warning will be given when this is likely to be\n",
       "significant.\n",
       "\n",
       "For central \\code{qt}, a C translation of\n",
       "\n",
       "Hill, G. W. (1970) Algorithm 396: Student's t-quantiles.\n",
       "\\emph{Communications of the ACM}, \\bold{13(10)}, 619--620.\n",
       "\n",
       "altered to take account of\n",
       "\n",
       "Hill, G. W. (1981) Remark on Algorithm 396, \\emph{ACM Transactions on\n",
       "Mathematical Software}, \\bold{7}, 250--1.\n",
       "\n",
       "The non-central case is done by inversion.\n",
       "\\end{Source}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)\n",
       "\\emph{The New S Language}.\n",
       "Wadsworth \\& Brooks/Cole. (Except non-central versions.)\n",
       "\n",
       "Johnson, N. L., Kotz, S. and Balakrishnan, N. (1995)\n",
       "\\emph{Continuous Univariate Distributions}, volume 2, chapters 28 and 31.\n",
       "Wiley, New York.\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\LinkA{Distributions}{Distributions} for other standard distributions, including\n",
       "\\code{\\LinkA{df}{df}} for the F distribution.\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "require(graphics)\n",
       "\n",
       "1 - pt(1:5, df = 1)\n",
       "qt(.975, df = c(1:10,20,50,100,1000))\n",
       "\n",
       "tt <- seq(0, 10, len = 21)\n",
       "ncp <- seq(0, 6, len = 31)\n",
       "ptn <- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))\n",
       "t.tit <- \"Non-central t - Probabilities\"\n",
       "image(tt, ncp, ptn, zlim = c(0,1), main = t.tit)\n",
       "persp(tt, ncp, ptn, zlim = 0:1, r = 2, phi = 20, theta = 200, main = t.tit,\n",
       "      xlab = \"t\", ylab = \"non-centrality parameter\",\n",
       "      zlab = \"Pr(T <= t)\")\n",
       "\n",
       "plot(function(x) dt(x, df = 3, ncp = 2), -3, 11, ylim = c(0, 0.32),\n",
       "     main = \"Non-central t - Density\", yaxs = \"i\")\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "TDist                  package:stats                   R Documentation\n",
       "\n",
       "_\bT_\bh_\be _\bS_\bt_\bu_\bd_\be_\bn_\bt _\bt _\bD_\bi_\bs_\bt_\br_\bi_\bb_\bu_\bt_\bi_\bo_\bn\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Density, distribution function, quantile function and random\n",
       "     generation for the t distribution with ‘df’ degrees of freedom\n",
       "     (and optional non-centrality parameter ‘ncp’).\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     dt(x, df, ncp, log = FALSE)\n",
       "     pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)\n",
       "     qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)\n",
       "     rt(n, df, ncp)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "    x, q: vector of quantiles.\n",
       "\n",
       "       p: vector of probabilities.\n",
       "\n",
       "       n: number of observations. If ‘length(n) > 1’, the length is\n",
       "          taken to be the number required.\n",
       "\n",
       "      df: degrees of freedom (> 0, maybe non-integer).  ‘df = Inf’ is\n",
       "          allowed.\n",
       "\n",
       "     ncp: non-centrality parameter delta; currently except for ‘rt()’,\n",
       "          only for ‘abs(ncp) <= 37.62’.  If omitted, use the central t\n",
       "          distribution.\n",
       "\n",
       "log, log.p: logical; if TRUE, probabilities p are given as log(p).\n",
       "\n",
       "lower.tail: logical; if TRUE (default), probabilities are P[X <= x],\n",
       "          otherwise, P[X > x].\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The t distribution with ‘df’ = n degrees of freedom has density\n",
       "\n",
       "     f(x) = Gamma((n+1)/2) / (sqrt(n pi) Gamma(n/2)) (1 + x^2/n)^-((n+1)/2)\n",
       "     \n",
       "     for all real x.  It has mean 0 (for n > 1) and variance n/(n-2)\n",
       "     (for n > 2).\n",
       "\n",
       "     The general _non-central_ t with parameters (df, Del) ‘= (df,\n",
       "     ncp)’ is defined as the distribution of T(df, Del) := (U + Del) /\n",
       "     sqrt(V/df) where U and V are independent random variables, U ~\n",
       "     N(0,1) and V ~ chi^2(df) (see Chisquare).\n",
       "\n",
       "     The most used applications are power calculations for t-tests:\n",
       "     Let T= (mX - m0) / (S/sqrt(n)) where mX is the ‘mean’ and S the\n",
       "     sample standard deviation (‘sd’) of X_1, X_2, ..., X_n which are\n",
       "     i.i.d. N(mu, sigma^2) Then T is distributed as non-central t with\n",
       "     ‘df’= n - 1 degrees of freedom and *n*on-*c*entrality *p*arameter\n",
       "     ‘ncp’ = (mu - m0) * sqrt(n)/sigma.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     ‘dt’ gives the density, ‘pt’ gives the distribution function, ‘qt’\n",
       "     gives the quantile function, and ‘rt’ generates random deviates.\n",
       "\n",
       "     Invalid arguments will result in return value ‘NaN’, with a\n",
       "     warning.\n",
       "\n",
       "     The length of the result is determined by ‘n’ for ‘rt’, and is the\n",
       "     maximum of the lengths of the numerical arguments for the other\n",
       "     functions.\n",
       "\n",
       "     The numerical arguments other than ‘n’ are recycled to the length\n",
       "     of the result.  Only the first elements of the logical arguments\n",
       "     are used.\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     Supplying ‘ncp = 0’ uses the algorithm for the non-central\n",
       "     distribution, which is not the same algorithm used if ‘ncp’ is\n",
       "     omitted.  This is to give consistent behaviour in extreme cases\n",
       "     with values of ‘ncp’ very near zero.\n",
       "\n",
       "     The code for non-zero ‘ncp’ is principally intended to be used for\n",
       "     moderate values of ‘ncp’: it will not be highly accurate,\n",
       "     especially in the tails, for large values.\n",
       "\n",
       "_\bS_\bo_\bu_\br_\bc_\be:\n",
       "\n",
       "     The central ‘dt’ is computed via an accurate formula provided by\n",
       "     Catherine Loader (see the reference in ‘dbinom’).\n",
       "\n",
       "     For the non-central case of ‘dt’, C code contributed by Claus\n",
       "     Ekstrøm based on the relationship (for x != 0) to the cumulative\n",
       "     distribution.\n",
       "\n",
       "     For the central case of ‘pt’, a normal approximation in the tails,\n",
       "     otherwise via ‘pbeta’.\n",
       "\n",
       "     For the non-central case of ‘pt’ based on a C translation of\n",
       "\n",
       "     Lenth, R. V. (1989). _Algorithm AS 243_ - Cumulative distribution\n",
       "     function of the non-central t distribution, _Applied Statistics_\n",
       "     *38*, 185-189.\n",
       "\n",
       "     This computes the lower tail only, so the upper tail suffers from\n",
       "     cancellation and a warning will be given when this is likely to be\n",
       "     significant.\n",
       "\n",
       "     For central ‘qt’, a C translation of\n",
       "\n",
       "     Hill, G. W. (1970) Algorithm 396: Student's t-quantiles.\n",
       "     _Communications of the ACM_, *13(10)*, 619-620.\n",
       "\n",
       "     altered to take account of\n",
       "\n",
       "     Hill, G. W. (1981) Remark on Algorithm 396, _ACM Transactions on\n",
       "     Mathematical Software_, *7*, 250-1.\n",
       "\n",
       "     The non-central case is done by inversion.\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n",
       "     Language_.  Wadsworth & Brooks/Cole. (Except non-central\n",
       "     versions.)\n",
       "\n",
       "     Johnson, N. L., Kotz, S. and Balakrishnan, N. (1995) _Continuous\n",
       "     Univariate Distributions_, volume 2, chapters 28 and 31.  Wiley,\n",
       "     New York.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     Distributions for other standard distributions, including ‘df’ for\n",
       "     the F distribution.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     require(graphics)\n",
       "     \n",
       "     1 - pt(1:5, df = 1)\n",
       "     qt(.975, df = c(1:10,20,50,100,1000))\n",
       "     \n",
       "     tt <- seq(0, 10, len = 21)\n",
       "     ncp <- seq(0, 6, len = 31)\n",
       "     ptn <- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))\n",
       "     t.tit <- \"Non-central t - Probabilities\"\n",
       "     image(tt, ncp, ptn, zlim = c(0,1), main = t.tit)\n",
       "     persp(tt, ncp, ptn, zlim = 0:1, r = 2, phi = 20, theta = 200, main = t.tit,\n",
       "           xlab = \"t\", ylab = \"non-centrality parameter\",\n",
       "           zlab = \"Pr(T <= t)\")\n",
       "     \n",
       "     plot(function(x) dt(x, df = 3, ncp = 2), -3, 11, ylim = c(0, 0.32),\n",
       "          main = \"Non-central t - Density\", yaxs = \"i\")\n",
       "     "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in Fisher.test(p = pw): object 'pw' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in Fisher.test(p = pw): object 'pw' not found\n"
     ]
    }
   ],
   "source": [
    "?pt\n",
    "Fisher.test(p=pw) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta-analysis based on assay-specific tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): could not find function \"Fisher.test\"\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): could not find function \"Fisher.test\"\n"
     ]
    }
   ],
   "source": [
    "Fisher.test(p=pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For either/any approach, since each gene was individually significant, one should expect support for the broader statement about the group to have substantially stronger statistical support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D.\n",
    "\n",
    "#### What do you conclude about the effect of hotsix on these six genes?\n",
    "\n",
    "The data provide strong evidence that loss of hotsix results in lower expression of these six genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "([Return to top.](#Mann-Whitney))\n",
    "\n",
    "* * *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
